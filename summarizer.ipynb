{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# def convert_to_txt(input_folder, output_folder):\n",
    "#     # Obtener la lista de archivos en la carpeta de entrada\n",
    "#     file_list = os.listdir(input_folder)\n",
    "\n",
    "#     for file_name in file_list:\n",
    "#         input_file_path = os.path.join(input_folder, file_name)\n",
    "\n",
    "#         # Verificar si es un archivo regular y si la extensión no es .txt\n",
    "#         if os.path.isfile(input_file_path) and not file_name.endswith('.txt'):\n",
    "#             # Leer el contenido del archivo\n",
    "#             with open(input_file_path, 'r', encoding='utf-8', errors='ignore') as original_file:\n",
    "#                 content = original_file.read()\n",
    "\n",
    "#             # Crear un nuevo archivo .txt en la carpeta de salida\n",
    "#             output_file_path = os.path.join(output_folder, file_name + '.txt')\n",
    "#             with open(output_file_path, 'w', encoding='utf-8') as txt_file:\n",
    "#                 txt_file.write(f\"$$$$ FILE_NAME: {file_name}$$$$\\n{content}\")\n",
    "\n",
    "# # Ruta de la carpeta de entrada que contiene los archivos a convertir\n",
    "# input_folder = 'C:/Users/felip/Documents/Concurso'\n",
    "\n",
    "# # Ruta de la carpeta de salida donde se guardarán los archivos de texto (.txt)\n",
    "# output_folder = 'docs'\n",
    "\n",
    "# # Crear la carpeta de salida si no existe\n",
    "# if not os.path.exists(output_folder):\n",
    "#     os.makedirs(output_folder)\n",
    "\n",
    "# convert_to_txt(input_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_BASE\"] = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.environ[\"AZURE_OPENAI_KEY\"]\n",
    "os.environ[\"OPENAI_API_VERSION\"] = \"2023-05-15\"\n",
    "os.environ[\"OPENAI_API_TYPE\"] = \"azure\"\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\") \n",
    "openai.api_version = \"2023-05-15\"\n",
    "openai.api_key = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "deployment_name = \"codecompass-gpt-16\"\n",
    "emb_name = \"codecompass_emb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(model_name=\"gpt-3.5-turbo-16k\", deployment_name=deployment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"docs\"\n",
    "loader = DirectoryLoader(directory)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hierarchy(directorio, nivel=0, max_archivos=15):\n",
    "    if not os.path.exists(directorio):\n",
    "        return \"El directorio no existe\"\n",
    "\n",
    "    if not os.path.isdir(directorio):\n",
    "        return \"La ruta proporcionada no es un directorio\"\n",
    "\n",
    "    resultado = \"\"\n",
    "\n",
    "    for item in os.listdir(directorio):\n",
    "        item_ruta = os.path.join(directorio, item)\n",
    "        indentacion = \"  \" * nivel\n",
    "\n",
    "        if os.path.isfile(item_ruta):\n",
    "            resultado += f\"{indentacion}- {item}\\n\"\n",
    "        elif os.path.isdir(item_ruta):\n",
    "            resultado += f\"{indentacion}+ {item}/\\n\"\n",
    "            if nivel < max_archivos:\n",
    "                resultado += get_hierarchy(item_ruta, nivel=nivel + 1, max_archivos=max_archivos)\n",
    "\n",
    "    return resultado\n",
    "\n",
    "directorio_a_analizar = 'C:/Users/felip/Documents/Concurso'\n",
    "hierarchy = get_hierarchy(directorio_a_analizar, max_archivos=15)\n",
    "# print(hierarchy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"converter.py\"\n",
    "prompt_template = f\"\"\"You are an assistant that helps developers document \\\n",
    "    or answer questions about software development projects. The project's \\\n",
    "    current folder hierarchy is denoted by #### characters and is the following: \\\n",
    "    ####{hierarchy}####.\\n\n",
    "    You have to document the following text that could be a piece of code or \\\n",
    "    a comment about the code, or simple text. The text is denoted by triple backticks \\\n",
    "    and is the following: \\n\n",
    "    ```{{text}}```\\n\n",
    "    1. The name of this file is at the beggining sorrounded by $$$$. \\n\n",
    "    2. Make sure that the documentation is correct and that it is consistent with the \\\n",
    "    project's hierarchy.\n",
    "    3. If you are not sure about the documentation, don't invent \\\n",
    "    anything and just write what you know. \n",
    "    4. Add the file name at the beggining of the documentation and use the format .md. \\\n",
    "    5. Don't put the hierarchy in any documentation.\n",
    "    6. Be the more concise as possible. \n",
    "    DOCUMENTATION:\"\"\"\n",
    "prompt = PromptTemplate.from_template(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "stuff_chain = StuffDocumentsChain(\n",
    "    llm_chain=llm_chain, document_variable_name=\"text\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 5000\n",
    "text_splitter = RecursiveCharacterTextSplitter(separators=[\"\\n\\n\", \"\\n\"], chunk_size=chunk_size, chunk_overlap=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.mapreduce import MapReduceChain\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains import ReduceDocumentsChain, MapReduceDocumentsChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get docs with more than 5000 chunks\n",
    "large_docs = []\n",
    "summarizes = []\n",
    "text_splitter = RecursiveCharacterTextSplitter(separators=[\"\\n\\n\", \"\\n\"], chunk_size=7000, chunk_overlap=100)\n",
    "summary_chain = load_summarize_chain(llm=llm, chain_type='map_reduce')\n",
    "\n",
    "for i, doc in enumerate(docs):\n",
    "    splitted_doc = []\n",
    "    summarized = \"\"\n",
    "    if llm.get_num_tokens(doc.page_content) >= chunk_size:\n",
    "        splitted_doc = text_splitter.split_documents([doc])\n",
    "        summarized = summary_chain.run(splitted_doc)\n",
    "        summarizes.append(summarized)\n",
    "        md_file_path = f'documentation/{i}.md'\n",
    "        save_text_as_md(summarized, md_file_path)\n",
    "    else:\n",
    "        text = stuff_chain.run([doc])\n",
    "        md_file_path = f'documentation/{i}.md'\n",
    "        save_text_as_md(text, md_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The code in the \"neoqa.ipynb\" file includes imports of libraries and modules for natural language processing and question-answering. It defines a class called \"Query\" with methods for loading and splitting documents, creating a database, and making queries. The code uses a sentence transformer model and a Chroma vector store for similarity search, and sets environment variables for the OpenAI API. The \"make_query\" method performs a similarity search and returns matching documents. The code encountered a ValueError due to missing input keys in the query.',\n",
       " 'The given code imports libraries, sets environment variables, loads data, and defines functions for natural language processing tasks. However, it throws a ValueError due to missing input keys. The code includes various functions and modules related to error handling, text manipulation, question answering, and retrieval. Some parts of the code are commented out. The code file is in IPython format with a version of 3 and can be exported as a Python file.',\n",
       " 'The given text includes code snippets and file paths related to Python programming. It involves tasks such as text summarization, document loading and processing, question answering, and API communication. It mentions the use of OpenAI and Azure OpenAI for question answering and various libraries and modules. The text appears to be part of a Jupyter Notebook file.']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
